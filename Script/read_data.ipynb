{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86af149b-f306-4d9d-922e-0eb40055d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8bf204-f0bd-46aa-b744-acb447ee6d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-01 00:34:54--  https://repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.15.0/spark-xml_2.12-0.15.0.jar\n",
      "Resolving repo1.maven.org (repo1.maven.org)... 146.75.32.209\n",
      "Connecting to repo1.maven.org (repo1.maven.org)|146.75.32.209|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 161962 (158K) [application/java-archive]\n",
      "Saving to: ‘spark-xml_2.12-0.15.0.jar’\n",
      "\n",
      "100%[======================================>] 161,962     --.-K/s   in 0.002s  \n",
      "\n",
      "2022-12-01 00:34:54 (97.4 MB/s) - ‘spark-xml_2.12-0.15.0.jar’ saved [161962/161962]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd /mnt/miniconda/bin/\n",
    "!wget https://repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.15.0/spark-xml_2.12-0.15.0.jar\n",
    "# !/mnt/miniconda/bin/pip install sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8196e485-8553-4580-8a6d-44b744faaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64643f52-82b2-4581-b733-b9ba9f2197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/01 00:35:50 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "22/12/01 00:36:02 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Capstone\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21db8ad9-51f5-41da-bdfd-7c5a4bfc76a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-68-254.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Capstone</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f223c07eb90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2b02ea-01be-4c7e-8d3a-8a28acdf5762",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o134.load.\n: java.lang.ClassNotFoundException: Failed to find data source: com.databricks.spark.xml. Please find packages at http://spark.apache.org/third-party-projects.html\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:674)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:728)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:230)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:214)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.ClassNotFoundException: com.databricks.spark.xml.DefaultSource\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:648)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:648)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:648)\n\t... 14 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12138/1040166930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'com.databricks.spark.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowTag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Job'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://dk1142-data/US_XML_AddFeed_20100101_20100107.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o134.load.\n: java.lang.ClassNotFoundException: Failed to find data source: com.databricks.spark.xml. Please find packages at http://spark.apache.org/third-party-projects.html\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:674)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:728)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:230)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:214)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.ClassNotFoundException: com.databricks.spark.xml.DefaultSource\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:648)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:648)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:648)\n\t... 14 more\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('com.databricks.spark.xml').options(rowTag='Job').load(\"s3://dk1142-data/US_XML_AddFeed_20100101_20100107.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124ec6e8-f747-4b8f-9452-f46cf1a99d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = spark.read.text(\"s3://dk1142-data/US_XML_AddFeed_20100101_20100107.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ee8073-d37d-4773-a8c7-90574daa2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(value='<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>'),\n",
       " Row(value='<Jobs>'),\n",
       " Row(value='<Job>'),\n",
       " Row(value='  <JobID>311017520</JobID>'),\n",
       " Row(value='  <CleanJobTitle>Pulmonologist/Critical Care Physician</CleanJobTitle>'),\n",
       " Row(value='  <JobDomain>www.resumes2work.com</JobDomain>'),\n",
       " Row(value='  <CanonCity>Missoula</CanonCity>'),\n",
       " Row(value='  <CanonCountry>USA</CanonCountry>'),\n",
       " Row(value='  <CanonState>MT</CanonState>'),\n",
       " Row(value='  <JobDate>2010-01-01</JobDate>'),\n",
       " Row(value=\"  <JobText>From: Company:  Providence Health &amp; Services ( ) Job Reference ID: 21228810  Category: other  Duration:  City, ST:  Missoula, Montana  Country:  United States Description: Missoula, Montana St. Patrick Hospital and Health Sciences Center and a highly regarded, physician-owned multispecialty clinic (50 providers) are partnering to bring a BC/BE Pulmonary/Critical Care/Intensivist to serve the community. Flexible practice options: Can be 100 percent Pulm outpatient joining another Pulmonologist in the clinic, or combined Pulm/Critical Care splitting time between the clinic and the ICU at St. Patrick (out of groups office down the hall from the ICU). Allergy consultation also available if interested. Nighttime hospitalist program in place. Not H-1B or J-1 visa eligible. Competitive guarantee plus excellent benefits package, including relocation. St. Patrick Hospital and Health Sciences Center, part of Providence Health and Services, is a pillar of the medical and business community in western Montana. Our 247-bed tertiary center has been named a Top 100 Hospital by Thomson (formerly Solucient). We house the world-renowned International Heart Institute of Montana and collaborate with the University of Montana and others to leverage scientific expertise for the benefit of our patients.  Missoula is a sophisticated university town of 65,000 located about halfway between Glacier and Yellowstone National Parks. The Clark Fork River runs through it, granite peaks surround it, and that famous Big Sky hangs over it all. The area offers unlimited recreational opportunities (ski, paddle, fish or hike out your back door) and numerous cultural amenities, including a symphony and an active theatre and arts scene. Missoula is a family-oriented community with great schools (elementary through university) and social activities year round. The climate is relatively mild; winters, for example, are warmer here than in much of the Midwest and Northeast. Western Montana summers are absolutely glorious, with long, adventure-inspiring days, starry nights and fresh mountain air. Providence Health and Services, a not-for-profit network of hospitals, clinics and physician partners in Alaska, California, Montana, Oregon and Washington. Providence has a proud 150-year history in the West, and we continue to grow with the communities we serve. With more than 300 physician opportunities in virtually all specialties, we offer physicians diverse lifestyle choices, flexible work arrangements and robust practice support. Learn more at www.providence.org/physicianopportunities.  Requirements: See Job Description.  Job Created: Mon Dec 28 2009 11:02:52 PM  Last Modified: Mon Dec 28 2009 11:02:52 PM  Resume Writing Get our professional resume writers to write your Pulmonologist/Critical Care Physician Needed! resume and you're 100% guaranteed to get  more interviews and job offers.  PayScale  Salary Calculator copyright 2003 - 2009 resumes2work |  Privacy Policy</JobText>\"),\n",
       " Row(value='  <JobURL>http://www.resumes2work.com/job.php?id=35860314</JobURL>'),\n",
       " Row(value='  <PostingHTML></PostingHTML>'),\n",
       " Row(value='  <Source>Company from Job Board</Source>'),\n",
       " Row(value='  <JobReferenceID>21228810</JobReferenceID>'),\n",
       " Row(value='  <Email></Email>'),\n",
       " Row(value='  <CanonEmployer>Providence Health &amp; Services</CanonEmployer>'),\n",
       " Row(value='  <Latitude>46.8575</Latitude>'),\n",
       " Row(value='  <Longitude>-114.042</Longitude>'),\n",
       " Row(value='  <CanonIntermediary></CanonIntermediary>'),\n",
       " Row(value='  <Telephone>604-806-9090</Telephone>'),\n",
       " Row(value='  <CanonJobTitle>Critical Care Physician</CanonJobTitle>'),\n",
       " Row(value='  <CanonCounty>Missoula</CanonCounty>'),\n",
       " Row(value='  <DivisionCode></DivisionCode>'),\n",
       " Row(value='  <MSA>33540: Metropolitan Statistical Area</MSA>'),\n",
       " Row(value='  <LMA>MT303354</LMA>'),\n",
       " Row(value='  <InternshipFlag>0</InternshipFlag>'),\n",
       " Row(value='  <ConsolidatedONET>29106900</ConsolidatedONET>'),\n",
       " Row(value='  <CanonCertification>'),\n",
       " Row(value='    <CanonCertification name=\"Board Certified/Board Eligible\" type=\"Certification\" />'),\n",
       " Row(value='  </CanonCertification>'),\n",
       " Row(value='  <CanonSkillClusters>Health Care: Emergency and Intensive Care;Specialized Skills|Specialized Skills|Specialized Skills</CanonSkillClusters>'),\n",
       " Row(value='  <CanonSkills>'),\n",
       " Row(value='    <CanonSkill name=\"Critical Care\" clusterName=\"Health Care: Emergency and Intensive Care;Specialized Skills\" />'),\n",
       " Row(value='    <CanonSkill name=\"Writing\" clusterName=\"Specialized Skills\" />'),\n",
       " Row(value='    <CanonSkill name=\"Allergy Consultation\" clusterName=\"Specialized Skills\" />'),\n",
       " Row(value='  </CanonSkills>'),\n",
       " Row(value='  <IsDuplicate>FALSE</IsDuplicate>'),\n",
       " Row(value='  <IsDuplicateOf>0</IsDuplicateOf>'),\n",
       " Row(value='  <CanonMaximumDegree></CanonMaximumDegree>'),\n",
       " Row(value='  <CanonMinimumDegree></CanonMinimumDegree>'),\n",
       " Row(value='  <CanonOtherDegrees></CanonOtherDegrees>'),\n",
       " Row(value='  <CanonPreferredDegrees></CanonPreferredDegrees>'),\n",
       " Row(value='  <CanonRequiredDegrees></CanonRequiredDegrees>'),\n",
       " Row(value='  <CIPCode></CIPCode>'),\n",
       " Row(value='  <StandardMajor></StandardMajor>'),\n",
       " Row(value='  <MaxExperience></MaxExperience>'),\n",
       " Row(value='  <MinExperience></MinExperience>'),\n",
       " Row(value='  <ConsolidatedInferredNAICS>622110</ConsolidatedInferredNAICS>'),\n",
       " Row(value='  <BGTOcc>29-1062.00</BGTOcc>'),\n",
       " Row(value='  <MaxAnnualSalary></MaxAnnualSalary>'),\n",
       " Row(value='  <MaxHourlySalary></MaxHourlySalary>'),\n",
       " Row(value='  <MinAnnualSalary></MinAnnualSalary>'),\n",
       " Row(value='  <MinHourlySalary></MinHourlySalary>'),\n",
       " Row(value='  <YearsOfExperience></YearsOfExperience>'),\n",
       " Row(value='  <CanonJobHours></CanonJobHours>'),\n",
       " Row(value='  <CanonJobType></CanonJobType>'),\n",
       " Row(value='  <CanonPostalCode>59801</CanonPostalCode>'),\n",
       " Row(value='  <CanonYearsOfExperienceCanonLevel></CanonYearsOfExperienceCanonLevel>'),\n",
       " Row(value='  <CanonYearsOfExperienceLevel></CanonYearsOfExperienceLevel>'),\n",
       " Row(value='  <ConsolidatedTitle>Critical Care Physician</ConsolidatedTitle>'),\n",
       " Row(value='  <Language>en</Language>'),\n",
       " Row(value='  <BGTSubOcc>Physician, Other</BGTSubOcc>'),\n",
       " Row(value='  <ConsolidatedDegreeLevels></ConsolidatedDegreeLevels>'),\n",
       " Row(value='  <MaxDegreeLevel></MaxDegreeLevel>'),\n",
       " Row(value='  <MinDegreeLevel></MinDegreeLevel>'),\n",
       " Row(value='</Job>'),\n",
       " Row(value='<Job>'),\n",
       " Row(value='  <JobID>311017521</JobID>'),\n",
       " Row(value='  <CleanJobTitle>Warehouse Associate</CleanJobTitle>')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.take(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3c361d-211c-4873-aa2a-c24b7a64357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
